{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predict conllu files given a trained model\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import logging\n",
        "import argparse\n",
        "import tarfile\n",
        "from pathlib import Path\n",
        "\n",
        "from allennlp.common import Params\n",
        "from allennlp.common.util import import_submodules\n",
        "from allennlp.models.archival import archive_model\n",
        "\n",
        "from udify import util\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
        "                    level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"archive\", type=str, help=\"The archive file\")\n",
        "parser.add_argument(\"input_file\", type=str, help=\"The input file to predict\")\n",
        "parser.add_argument(\"pred_file\", type=str, help=\"The output prediction file\")\n",
        "parser.add_argument(\"--eval_file\", default=None, type=str,\n",
        "                    help=\"If set, evaluate the prediction and store it in the given file\")\n",
        "parser.add_argument(\"--device\", default=0, type=int, help=\"CUDA device number; set to -1 for CPU\")\n",
        "parser.add_argument(\"--batch_size\", default=1, type=int, help=\"The size of each prediction batch\")\n",
        "parser.add_argument(\"--lazy\", action=\"store_true\", help=\"Lazy load dataset\")\n",
        "parser.add_argument(\"--raw_text\", action=\"store_true\", help=\"Input raw sentences, one per line in the input file.\")\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "import_submodules(\"udify\")\n",
        "\n",
        "archive_dir = Path(args.archive).resolve().parent\n",
        "\n",
        "if not os.path.isfile(archive_dir / \"weights.th\"):\n",
        "    with tarfile.open(args.archive) as tar:\n",
        "        tar.extractall(archive_dir)\n",
        "\n",
        "config_file = archive_dir / \"config.json\"\n",
        "\n",
        "overrides = {}\n",
        "if args.device is not None:\n",
        "    overrides[\"trainer\"] = {\"cuda_device\": args.device}\n",
        "if args.lazy:\n",
        "    overrides[\"dataset_reader\"] = {\"lazy\": args.lazy}\n",
        "configs = [Params(overrides), Params.from_file(config_file)]\n",
        "params = util.merge_configs(configs)\n",
        "\n",
        "predictor = \"udify_predictor\" if not args.raw_text else \"udify_text_predictor\"\n",
        "\n",
        "if not args.eval_file:\n",
        "    util.predict_model_with_archive(predictor, params, archive_dir, args.input_file, args.pred_file,\n",
        "                                    batch_size=args.batch_size)\n",
        "else:\n",
        "    util.predict_and_evaluate_model_with_archive(predictor, params, archive_dir, args.input_file,\n",
        "                                                 args.pred_file, args.eval_file, batch_size=args.batch_size)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}